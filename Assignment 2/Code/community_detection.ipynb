{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigating Graph Node Embeddings**\n",
    "\n",
    "Gian Favero | ECSE 556 | December 1st, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the .edge file associated with the “HumanNet Co-Expression of Human Genes (hn_HS_CX) network. The file will be cleaned up in such a way that only the relevant columns and values are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Node 1           Node 2    Weight\n",
      "0  ENSG00000284589  ENSG00000276821  0.000008\n",
      "1  ENSG00000284589  ENSG00000267534  0.000006\n",
      "2  ENSG00000284589  ENSG00000178802  0.000006\n",
      "3  ENSG00000284589  ENSG00000172772  0.000007\n",
      "4  ENSG00000284589  ENSG00000167751  0.000008\n"
     ]
    }
   ],
   "source": [
    "edges_df = pd.read_csv('9606.hn_HS_CX.edge', sep='\\t', header=None)\n",
    "edges_df = edges_df.iloc[:, :3]\n",
    "edges_df.columns = ['Node 1', 'Node 2', 'Weight']\n",
    "print(edges_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to start forming the adjacency matrix that represents the network. We can get a set of every node in the network and then augment the dataset to ensure the network is undirected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 10938\n",
      "Number of edges: 154387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 100555/154387 [00:08<00:04, 11875.11it/s]"
     ]
    }
   ],
   "source": [
    "# Get set of all nodes\n",
    "nodes = set(edges_df['Node 1'])\n",
    "nodes = nodes.union(set(edges_df['Node 2']))\n",
    "\n",
    "print('Number of nodes:', len(nodes))\n",
    "print('Number of edges:', len(edges_df))\n",
    "\n",
    "# Convert nodes to indices in edges_df\n",
    "nodes_dict = dict(zip(nodes, range(len(nodes))))\n",
    "edge_id_df = edges_df.copy()\n",
    "edge_id_df['Node 1'] = edge_id_df['Node 1'].map(nodes_dict)\n",
    "edge_id_df['Node 2'] = edge_id_df['Node 2'].map(nodes_dict)\n",
    "\n",
    "# Initialize adjacency matrix\n",
    "adj_mat = np.zeros((len(nodes), len(nodes)))\n",
    "\n",
    "# Fill adjacency matrix\n",
    "for i in tqdm(range(len(edge_id_df))):\n",
    "    row = edge_id_df.iloc[i]\n",
    "    adj_mat[int(row['Node 1']), int(row['Node 2'])] = row['Weight']\n",
    "\n",
    "# If there are any self-loops, remove them\n",
    "np.fill_diagonal(adj_mat, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  10825\n",
      "Number of edges:  154328\n"
     ]
    }
   ],
   "source": [
    "# Adjust adjacency matrix to be symmetric, undirected\n",
    "adj_mat = process_symmetric_entries(adj_mat)\n",
    "\n",
    "# Find all subgraphs and get list of nodes that belong to subgraphs with less than 5 nodes\n",
    "subgraphs = find_subgraphs(adj_mat)\n",
    "nodes_remove = nodes_to_remove(subgraphs, 5)\n",
    "\n",
    "# Remove nodes from adjacency matrix\n",
    "adj_mat = np.delete(adj_mat, nodes_remove, axis=0)\n",
    "adj_mat = np.delete(adj_mat, nodes_remove, axis=1)\n",
    "\n",
    "# Remove nodes from nodes list\n",
    "nodes = list(nodes)\n",
    "nodes = [nodes[i] for i in range(len(nodes)) if i not in nodes_remove]\n",
    "nodes_dict = dict(zip(nodes, range(len(nodes))))\n",
    "\n",
    "# Remove rows from edges_df that contain nodes that were removed\n",
    "edges_df = edges_df[edges_df['Node 1'].isin(nodes)]\n",
    "edges_df = edges_df[edges_df['Node 2'].isin(nodes)]\n",
    "\n",
    "edges_df['Node 1'] = edges_df['Node 1'].map(nodes_dict)\n",
    "edges_df['Node 2'] = edges_df['Node 2'].map(nodes_dict)\n",
    "\n",
    "# Normalize adjacency matrix by row\n",
    "tr_mat = adj_mat / adj_mat.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Print size of network\n",
    "print('Number of nodes: ', len(nodes))\n",
    "print('Number of edges: ', len(edges_df))\n",
    "\n",
    "# Choose 5000 random nodes to remove from network\n",
    "nodes_remove = np.random.choice(range(len(nodes)), size=9500, replace=False)\n",
    "\n",
    "# Remove nodes from adjacency matrix\n",
    "adj_mat = np.delete(adj_mat, nodes_remove, axis=0)\n",
    "adj_mat = np.delete(adj_mat, nodes_remove, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Community Detection**\n",
    "\n",
    "Using the same network, we can perform a community detection with various algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'community' has no attribute 'best_partition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/cim/faverog/ECSE556/ECSE556/Assignment 2/Code/community_detection.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprogress.mni.mcgill.ca/cim/faverog/ECSE556/ECSE556/Assignment%202/Code/community_detection.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m clauset_newman_clusters \u001b[39m=\u001b[39m {\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCommunity_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m: \u001b[39mlist\u001b[39m(community_set) \u001b[39mfor\u001b[39;00m i, community_set \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(clauset_newman_communities)}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprogress.mni.mcgill.ca/cim/faverog/ECSE556/ECSE556/Assignment%202/Code/community_detection.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Apply Louvain algorithm\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bprogress.mni.mcgill.ca/cim/faverog/ECSE556/ECSE556/Assignment%202/Code/community_detection.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m partition \u001b[39m=\u001b[39m community_louvain\u001b[39m.\u001b[39;49mbest_partition(G)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprogress.mni.mcgill.ca/cim/faverog/ECSE556/ECSE556/Assignment%202/Code/community_detection.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m louvain_clusters \u001b[39m=\u001b[39m {\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCommunity_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m: [node \u001b[39mfor\u001b[39;00m node, community_id \u001b[39min\u001b[39;00m partition\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m community_id \u001b[39m==\u001b[39m i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(partition\u001b[39m.\u001b[39mvalues())}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bprogress.mni.mcgill.ca/cim/faverog/ECSE556/ECSE556/Assignment%202/Code/community_detection.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Apply Girvan-Newman algorithm\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'community' has no attribute 'best_partition'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from networkx.algorithms import community\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Define graph\n",
    "G = nx.from_numpy_matrix(adj_mat)\n",
    "\n",
    "# Apply Clauset-Newman-Moore algorithm\n",
    "clauset_newman_communities = list(community.greedy_modularity_communities(G))\n",
    "clauset_newman_clusters = {f'Community_{i+1}': list(community_set) for i, community_set in enumerate(clauset_newman_communities)}\n",
    "\n",
    "# Apply Louvain algorithm\n",
    "partition = community_louvain.best_partition(G)\n",
    "louvain_clusters = {f'Community_{i+1}': [node for node, community_id in partition.items() if community_id == i] for i in set(partition.values())}\n",
    "\n",
    "# Apply Girvan-Newman algorithm\n",
    "girvan_newman_communities = next(community.girvan_newman(G))\n",
    "girvan_newman_clusters = {f'Community_{i+1}': list(community_set) for i, community_set in enumerate(girvan_newman_communities)}\n",
    "\n",
    "# Save the clusters to a dictionary\n",
    "all_clusters = {\n",
    "    'Clauset_Newman_Moore': clauset_newman_clusters,\n",
    "    'Louvain': louvain_clusters,\n",
    "    'Girvan_Newman': girvan_newman_clusters\n",
    "}\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open('community_clusters.pkl', 'wb') as file:\n",
    "    pickle.dump(all_clusters, file)\n",
    "\n",
    "print(\"Community clusters saved to 'community_clusters.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "# Load the clusters from the pickle file\n",
    "with open('Communities/community_clusters.pkl', 'rb') as file:\n",
    "    all_clusters = pickle.load(file)\n",
    "\n",
    "'''greedy_clusters = all_clusters['Clauset_Newman_Moore']\n",
    "greedy_color_map = {node: i for i, cluster in enumerate(greedy_clusters) for node in cluster}'''\n",
    "\n",
    "louvain_clusters = all_clusters['Louvain']\n",
    "louvain_color_map = {node: i for i, cluster in enumerate(louvain_clusters) for node in cluster}\n",
    "\n",
    "girvan_clusters = all_clusters['Girvan_Newman']\n",
    "girvan_color_map = {node: i for i, cluster in enumerate(girvan_clusters) for node in cluster}\n",
    "\n",
    "# Draw the graph with different colors for each cluster\n",
    "pos = nx.spring_layout(G)  # You can use different layout algorithms\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Girvan-Newman\n",
    "plt.subplot(131)\n",
    "nx.draw(G, pos, node_color=[girvan_color_map[node] for node in G.nodes], with_labels=True, cmap='viridis')\n",
    "plt.title('Girvan-Newman')\n",
    "\n",
    "# Greedy Modularity\n",
    "plt.subplot(132)\n",
    "nx.draw(G, pos, node_color=[greedy_color_map[node] for node in G.nodes], with_labels=True, cmap='viridis')\n",
    "plt.title('Greedy Modularity')\n",
    "\n",
    "# Louvain\n",
    "plt.subplot(133)\n",
    "nx.draw(G, pos, node_color=[louvain_color_map[node] for node in G.nodes], with_labels=True, cmap='viridis')\n",
    "plt.title('Louvain')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
